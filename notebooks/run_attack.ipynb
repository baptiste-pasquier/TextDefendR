{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scripts/attack.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from argparse import Namespace\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from textattack import AttackArgs, Attacker\n",
    "from textattack.attack_results import FailedAttackResult, SkippedAttackResult\n",
    "from textattack.datasets import Dataset\n",
    "\n",
    "import nlp_adversarial_attacks.attack.utils as utils\n",
    "from nlp_adversarial_attacks.attack import (\n",
    "    ModelWrapper,\n",
    "    get_attack_recipe,\n",
    "    predict,\n",
    "    save_results,\n",
    ")\n",
    "from nlp_adversarial_attacks.models.model_loading import load_target_model\n",
    "\n",
    "t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    # I/O settings\n",
    "    \"dir_dataset\": \"data/\",\n",
    "    \"dir_out\": \"attacks/\",\n",
    "    # Experiment settings\n",
    "    \"task_name\": \"sentiment\",\n",
    "    # Model parameters\n",
    "    \"model_name\": \"distilcamembert\",\n",
    "    \"pretrained_model_name_or_path\": \"baptiste-pasquier/distilcamembert-allocine\",\n",
    "    \"model_max_seq_len\": 512,\n",
    "    \"model_batch_size\": 32,\n",
    "    # Data parameters\n",
    "    \"dataset_name\": \"allocine\",\n",
    "    \"target_model_train_dataset\": \"allocine\",\n",
    "    # Attack parameters\n",
    "    \"attack_toolchain\": \"textattack\",\n",
    "    \"attack_name\": \"deepwordbug\",\n",
    "    \"attack_query_budget\": 0,\n",
    "    \"attack_n_samples\": 10,\n",
    "    # Other parameters\n",
    "    \"random_seed\": 0,\n",
    "}\n",
    "\n",
    "args = Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1cee4b5f4b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(args.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dir_dataset='data/', dir_out='attacks/', task_name='sentiment', model_name='distilcamembert', pretrained_model_name_or_path='baptiste-pasquier/distilcamembert-allocine', model_max_seq_len=512, model_batch_size=32, dataset_name='allocine', target_model_train_dataset='allocine', attack_toolchain='textattack', attack_name='deepwordbug', attack_query_budget=0, attack_n_samples=10, random_seed=0)\n",
      "Timestamp: 2023-03-17 19:11:10.736774\n"
     ]
    }
   ],
   "source": [
    "# setup output directory\n",
    "out_dir = Path(\n",
    "    args.dir_out,\n",
    "    args.dataset_name,\n",
    "    args.model_name,\n",
    "    args.attack_toolchain,\n",
    "    args.attack_name,\n",
    "    str(args.attack_n_samples),\n",
    ")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "logger = utils.get_logger(Path(out_dir, \"log.txt\"))\n",
    "logger.info(args)\n",
    "logger.info(f\"Timestamp: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save config file\n",
    "utils.cmd_args_to_yaml(args, Path(out_dir, \"config.yml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set no. labels\n",
    "num_labels = 2\n",
    "if args.dataset_name in [\"nuclear_energy\", \"climate-change_waterloo\"]:\n",
    "    num_labels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading trained model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoClassifier(\n",
       "  (classifier): CamembertForSequenceClassification(\n",
       "    (roberta): CamembertModel(\n",
       "      (embeddings): CamembertEmbeddings(\n",
       "        (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): CamembertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): CamembertLayer(\n",
       "            (attention): CamembertAttention(\n",
       "              (self): CamembertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): CamembertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): CamembertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): CamembertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): CamembertLayer(\n",
       "            (attention): CamembertAttention(\n",
       "              (self): CamembertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): CamembertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): CamembertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): CamembertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): CamembertLayer(\n",
       "            (attention): CamembertAttention(\n",
       "              (self): CamembertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): CamembertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): CamembertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): CamembertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): CamembertLayer(\n",
       "            (attention): CamembertAttention(\n",
       "              (self): CamembertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): CamembertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): CamembertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): CamembertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): CamembertLayer(\n",
       "            (attention): CamembertAttention(\n",
       "              (self): CamembertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): CamembertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): CamembertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): CamembertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): CamembertLayer(\n",
       "            (attention): CamembertAttention(\n",
       "              (self): CamembertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): CamembertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): CamembertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): CamembertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): CamembertClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained model\n",
    "logger.info(\"\\nLoading trained model...\")\n",
    "model = load_target_model(\n",
    "    model_name=args.model_name,\n",
    "    pretrained_model_name_or_path=args.pretrained_model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    max_seq_len=args.model_max_seq_len,\n",
    "    device=device,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0159, -3.4868],\n",
       "        [-2.6470,  3.0104]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "text_list = [\n",
    "    \"Mon dieu !!!!!!! Ce film à sacrément vieilli\",\n",
    "    \"Super film\",\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(text_list)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading test data set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Magnifique épopée, une belle histoire, touchan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Je n'ai pas aimé mais pourtant je lui mets 2 é...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Un dessin animé qui brille par sa féerie et se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Si c'est là le renouveau du cinéma français, c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Et pourtant on s’en Doutait !Second volet très...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>19995</td>\n",
       "      <td>je suis éventreur, arracheur, tailladeur, goug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>19996</td>\n",
       "      <td>Trémors 3 essouffle la série des trémors par u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19997</td>\n",
       "      <td>0/20 : Tout d’abord, la mise en scène est tout...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>19998</td>\n",
       "      <td>Un scénario très original mené par des personn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>19999</td>\n",
       "      <td>Ce dernier volet de la trilogie a beau être le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_index                                               text  label\n",
       "0               0  Magnifique épopée, une belle histoire, touchan...      1\n",
       "1               1  Je n'ai pas aimé mais pourtant je lui mets 2 é...      0\n",
       "2               2  Un dessin animé qui brille par sa féerie et se...      1\n",
       "3               3  Si c'est là le renouveau du cinéma français, c...      0\n",
       "4               4  Et pourtant on s’en Doutait !Second volet très...      0\n",
       "...           ...                                                ...    ...\n",
       "19995       19995  je suis éventreur, arracheur, tailladeur, goug...      1\n",
       "19996       19996  Trémors 3 essouffle la série des trémors par u...      0\n",
       "19997       19997  0/20 : Tout d’abord, la mise en scène est tout...      0\n",
       "19998       19998  Un scénario très original mené par des personn...      1\n",
       "19999       19999  Ce dernier volet de la trilogie a beau être le...      1\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the test set\n",
    "logger.info(\"\\nLoading test data set...\")\n",
    "dir_dataset = Path(args.dir_dataset, args.dataset_name)\n",
    "\n",
    "if os.path.exists(Path(dir_dataset, \"test.csv\")):\n",
    "    test_df = pd.read_csv(Path(dir_dataset, \"test.csv\"))\n",
    "\n",
    "elif Path(dir_dataset, \"data.csv\"):\n",
    "    test_df = pd.read_csv(Path(dir_dataset, \"data.csv\"))\n",
    "\n",
    "if \"index\" in test_df.columns:\n",
    "    del test_df[\"index\"]\n",
    "\n",
    "assert test_df.columns.tolist() == [\"text\", \"label\"]\n",
    "test_df = test_df.reset_index().rename(columns={\"index\": \"test_index\"})\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making prediction on the test set...\n",
      "No. test samples: 20,000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920fc092e13d4b348af1c3ad83ddd653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.970\n",
      "Time: 00:01:06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Magnifique épopée, une belle histoire, touchan...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Je n'ai pas aimé mais pourtant je lui mets 2 é...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Un dessin animé qui brille par sa féerie et se...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Si c'est là le renouveau du cinéma français, c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Et pourtant on s’en Doutait !Second volet très...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>19995</td>\n",
       "      <td>je suis éventreur, arracheur, tailladeur, goug...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>19996</td>\n",
       "      <td>Trémors 3 essouffle la série des trémors par u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19997</td>\n",
       "      <td>0/20 : Tout d’abord, la mise en scène est tout...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>19998</td>\n",
       "      <td>Un scénario très original mené par des personn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>19999</td>\n",
       "      <td>Ce dernier volet de la trilogie a beau être le...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_index                                               text  label  \\\n",
       "0               0  Magnifique épopée, une belle histoire, touchan...      1   \n",
       "1               1  Je n'ai pas aimé mais pourtant je lui mets 2 é...      0   \n",
       "2               2  Un dessin animé qui brille par sa féerie et se...      1   \n",
       "3               3  Si c'est là le renouveau du cinéma français, c...      0   \n",
       "4               4  Et pourtant on s’en Doutait !Second volet très...      0   \n",
       "...           ...                                                ...    ...   \n",
       "19995       19995  je suis éventreur, arracheur, tailladeur, goug...      1   \n",
       "19996       19996  Trémors 3 essouffle la série des trémors par u...      0   \n",
       "19997       19997  0/20 : Tout d’abord, la mise en scène est tout...      0   \n",
       "19998       19998  Un scénario très original mené par des personn...      1   \n",
       "19999       19999  Ce dernier volet de la trilogie a beau être le...      1   \n",
       "\n",
       "       pred  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "19995     0  \n",
       "19996     0  \n",
       "19997     0  \n",
       "19998     1  \n",
       "19999     1  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate predictions on the test set\n",
    "t = time.time()\n",
    "logger.info(\"Making prediction on the test set...\")\n",
    "pred_test, proba_test = predict(args, model, test_df, device, logger=logger)\n",
    "test_df[\"pred\"] = pred_test\n",
    "logger.info(f\"Time: {time.strftime('%H:%M:%S', time.gmtime(time.time()-t))}\")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label names and encode labels if necessary\n",
    "if args.dataset_name in [\n",
    "    \"wikipedia\",\n",
    "    \"civil_comments\",\n",
    "    \"hatebase\",\n",
    "    \"wikipedia_personal\",\n",
    "    \"wikipedia_aggression\",\n",
    "    \"reddit_dataset\",\n",
    "    \"gab_dataset\",\n",
    "]:\n",
    "    label_names = [\"non-toxic\", \"toxic\"]\n",
    "\n",
    "elif args.dataset_name == \"fnc1\":\n",
    "    label_map = {\"agree\": 0, \"disagree\": 1, \"discuss\": 2, \"unrelated\": 3}\n",
    "    inverse_label_map = {v: k for k, v in label_map.items()}\n",
    "    label_names = [inverse_label_map[i] for i in range(len(inverse_label_map))]\n",
    "\n",
    "elif args.dataset_name in [\"imdb\", \"sst\", \"allocine\"]:\n",
    "    label_names = [\"negative\", \"positive\"]\n",
    "\n",
    "elif args.dataset_name in [\"nuclear_energy\", \"climate-change_waterloo\"]:\n",
    "    label_names = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"unknown dataset {args.dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Magnifique épopée, une belle histoire, touchan...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Je n'ai pas aimé mais pourtant je lui mets 2 é...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Un dessin animé qui brille par sa féerie et se...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Si c'est là le renouveau du cinéma français, c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Et pourtant on s’en Doutait !Second volet très...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>19994</td>\n",
       "      <td>On y trouve même pas le divertissement. A reje...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>19996</td>\n",
       "      <td>Trémors 3 essouffle la série des trémors par u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19997</td>\n",
       "      <td>0/20 : Tout d’abord, la mise en scène est tout...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>19998</td>\n",
       "      <td>Un scénario très original mené par des personn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>19999</td>\n",
       "      <td>Ce dernier volet de la trilogie a beau être le...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19407 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_index                                               text  label  \\\n",
       "0               0  Magnifique épopée, une belle histoire, touchan...      1   \n",
       "1               1  Je n'ai pas aimé mais pourtant je lui mets 2 é...      0   \n",
       "2               2  Un dessin animé qui brille par sa féerie et se...      1   \n",
       "3               3  Si c'est là le renouveau du cinéma français, c...      0   \n",
       "4               4  Et pourtant on s’en Doutait !Second volet très...      0   \n",
       "...           ...                                                ...    ...   \n",
       "19994       19994  On y trouve même pas le divertissement. A reje...      0   \n",
       "19996       19996  Trémors 3 essouffle la série des trémors par u...      0   \n",
       "19997       19997  0/20 : Tout d’abord, la mise en scène est tout...      0   \n",
       "19998       19998  Un scénario très original mené par des personn...      1   \n",
       "19999       19999  Ce dernier volet de la trilogie a beau être le...      1   \n",
       "\n",
       "       pred  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "19994     0  \n",
       "19996     0  \n",
       "19997     0  \n",
       "19998     1  \n",
       "19999     1  \n",
       "\n",
       "[19407 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# focus on correctly predicted TOXIC instances for abuse\n",
    "if args.task_name == \"abuse\":\n",
    "    temp_df = test_df[(test_df[\"label\"] == 1) & (test_df[\"pred\"] == 1)].copy()\n",
    "\n",
    "# focus on correctly predicted instances\n",
    "else:\n",
    "    temp_df = test_df[test_df[\"label\"] == test_df[\"pred\"]].copy()\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning attacks...\n",
      "No. test: 20,000, no. candidates: 10\n"
     ]
    }
   ],
   "source": [
    "# attack text prioritizing longer text instances\n",
    "# temp_df[\"length\"] = temp_df[\"text\"].apply(lambda x: len(x.split()))\n",
    "# temp_df = temp_df.sort_values(\"length\", ascending=False)\n",
    "if args.attack_n_samples:\n",
    "    temp_df = temp_df[: args.attack_n_samples]\n",
    "temp_df = temp_df.reset_index(drop=True)\n",
    "logger.info(\"\\nBeginning attacks...\")\n",
    "logger.info(f\"No. test: {len(test_df):,}, no. candidates: {len(temp_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result containers\n",
    "results = []\n",
    "t = time.time()  # total time\n",
    "\n",
    "# selected indices information\n",
    "y_test = temp_df[\"label\"].values\n",
    "test_indices = temp_df[\"test_index\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.camembert.modeling_camembert.CamembertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    }
   ],
   "source": [
    "# TextAttack\n",
    "\n",
    "# prepare data\n",
    "dataset = Dataset(list(zip(temp_df[\"text\"], temp_df[\"label\"])), label_names=label_names)\n",
    "\n",
    "# prepare attacker\n",
    "model_wrapper = ModelWrapper(model)\n",
    "attack_recipe = get_attack_recipe(args.attack_toolchain, args.attack_name)\n",
    "attack = attack_recipe.build(model_wrapper)\n",
    "attack_args = AttackArgs(\n",
    "    num_examples=-1,\n",
    "    query_budget=args.attack_query_budget,\n",
    "    log_summary_to_json=Path(out_dir, \"summary.json\").as_posix(),\n",
    ")\n",
    "attacker = Attacker(attack, dataset, attack_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Logging Summary to JSON at path attacks/allocine/distilcamembert/textattack/deepwordbug/10/summary.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  unk\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  CompositeTransformation(\n",
      "    (0): WordSwapNeighboringCharacterSwap(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (1): WordSwapRandomCharacterSubstitution(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (2): WordSwapRandomCharacterDeletion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (3): WordSwapRandomCharacterInsertion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    )\n",
      "  (constraints): \n",
      "    (0): LevenshteinEditDistance(\n",
      "        (max_edit_distance):  30\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:03,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  10%|█         | 1/10 [00:00<00:05,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Positive (100%)]] --> [[Negative (63%)]]\n",
      "\n",
      "[[Magnifique]] [[épopée]], une [[belle]] [[histoire]], [[touchante]] [[avec]] des acteurs qui [[interprètent]] très bien leur rôles (Mel Gibson, Heath Ledger, Jason Isaacs...), [[le]] genre de [[film]] qui se savoure en [[famille]]! :)\n",
      "\n",
      "[[Mcgnifique]] [[éApopée]], une [[elle]] [[istoire]], [[touclhante]] [[arvec]] des acteurs qui [[itnerprètent]] très bien leur rôles (Mel Gibson, Heath Ledger, Jason Isaacs...), [[We]] genre de [[fil]] qui se savoure en [[faimlle]]! :)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  30%|███       | 3/10 [00:01<00:02,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (100%)]] --> [[Positive (58%)]]\n",
      "\n",
      "Je n'ai [[pas]] [[aimé]] mais pourtant je lui [[mets]] 2 [[étoiles]] car l'expérience est louable. Rien de conventionnel ici. Une visite E.T. mais jonchée d'idées /- originales. Le soucis, tout ceci avait-il vraiment sa place dans un film de S.F. tirant sur l'horreur ? Voici un film qui, à l'inverse de tant d'autres qui y ont droit, mériterait peut-être un remake.\n",
      "\n",
      "Je n'ai [[pms]] [[Yaimé]] mais pourtant je lui [[meVts]] 2 [[étoiBles]] car l'expérience est louable. Rien de conventionnel ici. Une visite E.T. mais jonchée d'idées /- originales. Le soucis, tout ceci avait-il vraiment sa place dans un film de S.F. tirant sur l'horreur ? Voici un film qui, à l'inverse de tant d'autres qui y ont droit, mériterait peut-être un remake.\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[Positive (99%)]] --> [[Negative (84%)]]\n",
      "\n",
      "Un dessin animé qui [[brille]] [[par]] sa [[féerie]] et ses chansons.\n",
      "\n",
      "Un dessin animé qui [[bille]] [[paT]] sa [[féerdie]] et ses chansons.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4:  40%|████      | 4/10 [00:01<00:02,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[Negative (100%)]] --> [[Positive (74%)]]\n",
      "\n",
      "[[Si]] c'est là le renouveau du cinéma français, c'est tout de même foutrement [[chiant]]. [[Si]] l'objet est très stylisé et la tension palpable, le film paraît plutôt creux.\n",
      "\n",
      "[[gi]] c'est là le renouveau du cinéma français, c'est tout de même foutrement [[chiaft]]. [[iS]] l'objet est très stylisé et la tension palpable, le film paraît plutôt creux.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5:  50%|█████     | 5/10 [00:01<00:01,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[Negative (100%)]] --> [[Positive (76%)]]\n",
      "\n",
      "[[Et]] pourtant on s’[[en]] Doutait ![[Second]] [[volet]] [[très]] [[mauvais]], sans [[fraîcheur]] [[et]] [[particulièrement]] [[lourdingue]]. [[Quel]] dommage.\n",
      "\n",
      "[[t]] pourtant on s’[[Fn]] Doutait ![[eScond]] [[svolet]] [[trè]] [[mavuais]], sans [[fracheur]] [[Pet]] [[partculièrement]] [[lordingue]]. [[uel]] dommage.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 1 / 0 / 6:  60%|██████    | 6/10 [00:17<00:11,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[Positive (100%)]] --> [[[FAILED]]]\n",
      "\n",
      "Vous reprendrez bien un peu d'été ? Ce film je le voyais comme un mélange de Rohmer et de Rozier, un film de vacances, j'adore ça, un truc beau et pur qui dit des choses sur la vie, l'amour, les filles, les vacances. Un film qui se regarde en sirotant une boisson fraîche en écoutant les grillons ! Sauf qu'en fait non ! On a un film foutraque au possible qui reprend les codes justement de Rohmer voir Godard, enfin la Nouvelle Vague en général dans sa première partie (jusqu'à même finir sur une partie qui ressemblerait à du Kusturica), mais en beaucoup plus léger et décalé. Le film n'en a rien à foutre de rien, il ose tout, n'a peur de rien et ça c'est bon. C'est sans doute le film le plus drôle de 2013, mais tout simplement l'un des meilleurs tout court. Le film qui nous sort des dialogues qui pourraient sortir d'un mauvais Godard (oxymore) sur un ton what the fuckesque… raconte des anecdotes débiles au souhait face caméra… et pourtant, il y a quelque chose dans ce film survolté. Il y a du beau. Ces scènes dans la neige, c'est tendre, c'est beau, ça tranche avec le reste et ça donne du coeur à l'amourette, ça aide à le faire paraître comme une évidence. Et puis on a cette scène que je trouve sublime qui m'a profondément émue, cette scène où le docteur Placenta devient tout à coup sérieux et parle de cette date où chaque année il repense à cette fille et au fait qu'une année de plus le sépare d'elle. C'est horrible comme concept et pourtant tellement vrai et sincère. C'est vraiment troublant. Et encore une fois la scène d'avant est très drôle et là, un petit moment de douceur avant de repartir sur le train effréné ! Et il y a ces fesses… Et le plus beau c'est qu'à la fin Vimala Pons a un petit air d'Anna Karina ! Film fout, étonnant, percutant, drôle, beau, triste ! C'est foutrement cool !\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 1 / 0 / 7:  70%|███████   | 7/10 [00:18<00:07,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[Positive (100%)]] --> [[Negative (56%)]]\n",
      "\n",
      "[[Terrible]] histoire que ces êtres sans amour, ces êtres lisses et frustres qui passent à côté de leur vie. Quelle [[leçon]] Monsieur Brizé! Vous avez tout dit, tout filmé jusqu'au moindre détail. tout est beau et terrifiant jusqu'à la scène finale qui nous liquéfie, un Vincent Lindon regardant la vie fixement sans oser la toucher ni la prendre dans ses bras, une Hélène Vincent qui attend, qui attend... Mon Dieu Monsieur Brizé, continuez....\n",
      "\n",
      "[[Terirble]] histoire que ces êtres sans amour, ces êtres lisses et frustres qui passent à côté de leur vie. Quelle [[leçno]] Monsieur Brizé! Vous avez tout dit, tout filmé jusqu'au moindre détail. tout est beau et terrifiant jusqu'à la scène finale qui nous liquéfie, un Vincent Lindon regardant la vie fixement sans oser la toucher ni la prendre dans ses bras, une Hélène Vincent qui attend, qui attend... Mon Dieu Monsieur Brizé, continuez....\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 1 / 0 / 8:  80%|████████  | 8/10 [00:18<00:04,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[Positive (100%)]] --> [[Negative (88%)]]\n",
      "\n",
      "Un [[très]] joli [[film]], qui [[ressemble]] à un téléfilm mais [[qui]] a le mérite d'être émouvant et proche de ses personnages. Magimel est vraiment [[très]] [[bon]] et [[l'histoire]] est [[touchante]]\n",
      "\n",
      "Un [[trè]] joli [[filV]], qui [[ressemlbe]] à un téléfilm mais [[Kqui]] a le mérite d'être émouvant et proche de ses personnages. Magimel est vraiment [[rès]] [[boDn]] et [[l'hpstoire]] est [[tuchante]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 2 / 0 / 9:  90%|█████████ | 9/10 [00:21<00:02,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[Negative (100%)]] --> [[[FAILED]]]\n",
      "\n",
      "Mais comment certaines personnes ont pus lui mettre 5/5 et donc dire indirectement que c'est un chef-d'œuvre ??? Et comment a-t-il fait pour sortir au cinéma et non en DTV ??? C'est pas un film que l'on regarde dans une salle obscur ça, pour moi ça ressemble plus à un téléfilm que l'on visionne un dimanche pluvieux pour que les enfants arrête de nous casser les pieds ! Et puis, le scénario avec le chien que devient le meilleur ami du gosse, c'est du vu et revu (un cliché) ! L'acteur principal est quant à lui aussi agaçant que son personnage ! Les suites ont l'air aussi mauvaises que Buddy Star des Paniers étant donné que l'histoire est quasiment la même (pour moi ça c'est pas des suites, c'est plutôt une succession de petits reboots inutiles). Reste regardable pour les moins de 10 ans (et encore, même moi à 6 ans, je n'aurais pas aimé).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 2 / 0 / 10: 100%|██████████| 10/10 [00:22<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[Positive (100%)]] --> [[Negative (62%)]]\n",
      "\n",
      "[[LE]] film de [[mon]] enfance , il a un peu vieilli maintenant , mais l'ours reste toujours impressionnant, il est bien réel contrairement au film 'the Revenant\" . Ce n'est surement pas un chef-d'œuvre [[mais]] je le trouve bien réalise , captivant , beaux et accompagné d'une superbe musique. Le gros points noir c'est la facilité qu'ils ont a créer des peaux , des pièges , et rester longtemps sans manger....mais on oublie assez vite ces [[erreurs]] grâce a un casting sympathique et aux décors naturels. Un vieux film mais qui reste [[toujours]] un [[bon]] [[film]].\n",
      "\n",
      "[[L]] film de [[on]] enfance , il a un peu vieilli maintenant , mais l'ours reste toujours impressionnant, il est bien réel contrairement au film 'the Revenant\" . Ce n'est surement pas un chef-d'œuvre [[masi]] je le trouve bien réalise , captivant , beaux et accompagné d'une superbe musique. Le gros points noir c'est la facilité qu'ils ont a créer des peaux , des pièges , et rester longtemps sans manger....mais on oublie assez vite ces [[ereurs]] grâce a un casting sympathique et aux décors naturels. Un vieux film mais qui reste [[toujurs]] un [[bno]] [[fim]].\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+-------+\n",
      "| Attack Results                |       |\n",
      "+-------------------------------+-------+\n",
      "| Number of successful attacks: | 8     |\n",
      "| Number of failed attacks:     | 2     |\n",
      "| Number of skipped attacks:    | 0     |\n",
      "| Original accuracy:            | 100.0 |\n",
      "| Accuracy under attack:        | 20.0  |\n",
      "| Attack success rate:          | 80.0  |\n",
      "| Average perturbed word %:     | 22.47 |\n",
      "| Average num. words per input: | 82.4  |\n",
      "| Avg num queries:              | 137.5 |\n",
      "+-------------------------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "attack_results = attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 (dataset=allocine, model=distilcamembert, attack=deepwordbug, no. queries=78):\n",
      "Positive (100%) --> Negative (63%)\n",
      "\n",
      "Result 2 (dataset=allocine, model=distilcamembert, attack=deepwordbug, no. queries=77):\n",
      "Negative (100%) --> Positive (58%)\n",
      "\n",
      "Result 3 (dataset=allocine, model=distilcamembert, attack=deepwordbug, no. queries=24):\n",
      "Positive (99%) --> Negative (84%)\n",
      "\n",
      "Result 4 (dataset=allocine, model=distilcamembert, attack=deepwordbug, no. queries=41):\n",
      "Negative (100%) --> Positive (74%)\n",
      "\n",
      "Result 5 (dataset=allocine, model=distilcamembert, attack=deepwordbug, no. queries=64):\n",
      "Negative (100%) --> Positive (76%)\n",
      "\n",
      "Result 6 (dataset=allocine, model=distilcamembert, attack=deepwordbug, no. queries=512):\n",
      "Positive (100%) --> [FAILED]\n",
      "\n",
      "Result 7 (dataset=allocine, model=distilcamembert, attack=deepwordbug, no. queries=86):\n",
      "Positive (100%) --> Negative (56%)\n",
      "\n",
      "Result 8 (dataset=allocine, model=distilcamembert, attack=deepwordbug, no. queries=61):\n",
      "Positive (100%) --> Negative (88%)\n",
      "\n",
      "Result 9 (dataset=allocine, model=distilcamembert, attack=deepwordbug, no. queries=294):\n",
      "Negative (100%) --> [FAILED]\n",
      "\n",
      "Result 10 (dataset=allocine, model=distilcamembert, attack=deepwordbug, no. queries=138):\n",
      "Positive (100%) --> Negative (62%)\n",
      "\n",
      "\n",
      "Saving results to attacks\\allocine\\distilcamembert\\textattack\\deepwordbug\\10/...\n",
      "\n",
      "Results:\n",
      "    scenario     target_model target_model_train_dataset attack_toolchain  \\\n",
      "0  sentiment  distilcamembert                   allocine       textattack   \n",
      "1  sentiment  distilcamembert                   allocine       textattack   \n",
      "2  sentiment  distilcamembert                   allocine       textattack   \n",
      "3  sentiment  distilcamembert                   allocine       textattack   \n",
      "4  sentiment  distilcamembert                   allocine       textattack   \n",
      "\n",
      "   attack_name target_dataset  test_index  \\\n",
      "0  deepwordbug       allocine           0   \n",
      "1  deepwordbug       allocine           1   \n",
      "2  deepwordbug       allocine           2   \n",
      "3  deepwordbug       allocine           3   \n",
      "4  deepwordbug       allocine           4   \n",
      "\n",
      "                                       original_text  \\\n",
      "0  Magnifique épopée, une belle histoire, touchan...   \n",
      "1  Je n'ai pas aimé mais pourtant je lui mets 2 é...   \n",
      "2  Un dessin animé qui brille par sa féerie et se...   \n",
      "3  Si c'est là le renouveau du cinéma français, c...   \n",
      "4  Et pourtant on s’en Doutait !Second volet très...   \n",
      "\n",
      "                                      perturbed_text  ground_truth  \\\n",
      "0  Mcgnifique éApopée, une elle istoire, touclhan...             1   \n",
      "1  Je n'ai pms Yaimé mais pourtant je lui meVts 2...             0   \n",
      "2  Un dessin animé qui bille paT sa féerdie et se...             1   \n",
      "3  gi c'est là le renouveau du cinéma français, c...             0   \n",
      "4  t pourtant on s’Fn Doutait !eScond svolet trè ...             0   \n",
      "\n",
      "                               original_output  \\\n",
      "0   [0.0017641951562836766, 0.998235821723938]   \n",
      "1   [0.9981809854507446, 0.001819050288759172]   \n",
      "2    [0.006273656152188778, 0.993726372718811]   \n",
      "3  [0.9992220401763916, 0.0007778950384818017]   \n",
      "4  [0.9990242719650269, 0.0009757408406585455]   \n",
      "\n",
      "                            perturbed_output   status  num_queries  \\\n",
      "0   [0.6277955174446106, 0.3722044825553894]  success           78   \n",
      "1   [0.4200280010700226, 0.5799720287322998]  success           77   \n",
      "2  [0.8436582684516907, 0.15634173154830933]  success           24   \n",
      "3  [0.25986334681510925, 0.7401366233825684]  success           41   \n",
      "4     [0.236352801322937, 0.763647198677063]  success           64   \n",
      "\n",
      "   frac_words_changed  \n",
      "0            0.333333  \n",
      "1            0.065574  \n",
      "2            0.272727  \n",
      "3            0.107143  \n",
      "4            0.647059  \n"
     ]
    }
   ],
   "source": [
    "# attack test set\n",
    "for i, attack_result in enumerate(attack_results):\n",
    "    # get attack status\n",
    "    status = \"success\"\n",
    "    if isinstance(attack_result, FailedAttackResult):\n",
    "        status = \"failed\"\n",
    "    elif isinstance(attack_result, SkippedAttackResult):\n",
    "        status = \"skipped\"\n",
    "\n",
    "    # get original and peturbed objects\n",
    "    og = attack_result.original_result\n",
    "    pp = attack_result.perturbed_result\n",
    "\n",
    "    num_words_changed = len(og.attacked_text.all_words_diff(pp.attacked_text))\n",
    "\n",
    "    result = {\n",
    "        \"scenario\": args.task_name,\n",
    "        \"target_model\": args.model_name,\n",
    "        \"target_model_train_dataset\": args.target_model_train_dataset,\n",
    "        \"attack_toolchain\": args.attack_toolchain,\n",
    "        \"attack_name\": args.attack_name,\n",
    "        \"target_dataset\": args.dataset_name,\n",
    "        \"test_index\": test_indices[i],\n",
    "        \"ground_truth\": y_test[i],\n",
    "        \"original_text\": og.attacked_text.text,\n",
    "        \"perturbed_text\": pp.attacked_text.text,\n",
    "        \"original_output\": og.raw_output.tolist(),\n",
    "        \"perturbed_output\": pp.raw_output.tolist(),\n",
    "        \"status\": status,\n",
    "        \"num_queries\": attack_result.num_queries,\n",
    "    }\n",
    "    try:\n",
    "        result[\"frac_words_changed\"] = num_words_changed / len(og.attacked_text.words)\n",
    "    except ZeroDivisionError:\n",
    "        result[\"frac_words_changed\"] = -1\n",
    "    results.append(result)\n",
    "\n",
    "    s = \"Result {} (dataset={}, model={}, attack={}, no. queries={:,}):\"\n",
    "    logger.info(\n",
    "        s.format(\n",
    "            i + 1,\n",
    "            args.dataset_name,\n",
    "            args.model_name,\n",
    "            args.attack_name,\n",
    "            result[\"num_queries\"],\n",
    "        )\n",
    "    )\n",
    "    logger.info(attack_result.goal_function_result_str() + \"\\n\")\n",
    "    # logger.info(attack_result.__str__(color_method=\"ansi\"))\n",
    "\n",
    "# save leftover results\n",
    "logger.info(f\"\\nSaving results to {out_dir}/...\")\n",
    "save_results(results, out_dir, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attack time: 00:00:22\n",
      "Total time: 00:01:36\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"\\nAttack time: {time.strftime('%H:%M:%S', time.gmtime(time.time()-t))}\")\n",
    "logger.info(f\"Total time: {time.strftime('%H:%M:%S', time.gmtime(time.time()-start))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>target_model</th>\n",
       "      <th>target_model_train_dataset</th>\n",
       "      <th>attack_toolchain</th>\n",
       "      <th>attack_name</th>\n",
       "      <th>target_dataset</th>\n",
       "      <th>test_index</th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>original_output</th>\n",
       "      <th>perturbed_output</th>\n",
       "      <th>status</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>frac_words_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>deepwordbug</td>\n",
       "      <td>allocine</td>\n",
       "      <td>0</td>\n",
       "      <td>Magnifique épopée, une belle histoire, touchan...</td>\n",
       "      <td>Mcgnifique éApopée, une elle istoire, touclhan...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0017641951562836766, 0.998235821723938]</td>\n",
       "      <td>[0.6277955174446106, 0.3722044825553894]</td>\n",
       "      <td>success</td>\n",
       "      <td>78</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>deepwordbug</td>\n",
       "      <td>allocine</td>\n",
       "      <td>1</td>\n",
       "      <td>Je n'ai pas aimé mais pourtant je lui mets 2 é...</td>\n",
       "      <td>Je n'ai pms Yaimé mais pourtant je lui meVts 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9981809854507446, 0.001819050288759172]</td>\n",
       "      <td>[0.4200280010700226, 0.5799720287322998]</td>\n",
       "      <td>success</td>\n",
       "      <td>77</td>\n",
       "      <td>0.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>deepwordbug</td>\n",
       "      <td>allocine</td>\n",
       "      <td>2</td>\n",
       "      <td>Un dessin animé qui brille par sa féerie et se...</td>\n",
       "      <td>Un dessin animé qui bille paT sa féerdie et se...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.006273656152188778, 0.993726372718811]</td>\n",
       "      <td>[0.8436582684516907, 0.15634173154830933]</td>\n",
       "      <td>success</td>\n",
       "      <td>24</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>deepwordbug</td>\n",
       "      <td>allocine</td>\n",
       "      <td>3</td>\n",
       "      <td>Si c'est là le renouveau du cinéma français, c...</td>\n",
       "      <td>gi c'est là le renouveau du cinéma français, c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9992220401763916, 0.0007778950384818017]</td>\n",
       "      <td>[0.25986334681510925, 0.7401366233825684]</td>\n",
       "      <td>success</td>\n",
       "      <td>41</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>deepwordbug</td>\n",
       "      <td>allocine</td>\n",
       "      <td>4</td>\n",
       "      <td>Et pourtant on s’en Doutait !Second volet très...</td>\n",
       "      <td>t pourtant on s’Fn Doutait !eScond svolet trè ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9990242719650269, 0.0009757408406585455]</td>\n",
       "      <td>[0.236352801322937, 0.763647198677063]</td>\n",
       "      <td>success</td>\n",
       "      <td>64</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>deepwordbug</td>\n",
       "      <td>allocine</td>\n",
       "      <td>5</td>\n",
       "      <td>Vous reprendrez bien un peu d'été ? Ce film je...</td>\n",
       "      <td>Vous reprendrez bien un peu d'été ? Ce film je...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0016408609226346016, 0.9983591437339783]</td>\n",
       "      <td>[0.017444437369704247, 0.9825555086135864]</td>\n",
       "      <td>failed</td>\n",
       "      <td>512</td>\n",
       "      <td>0.081081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>deepwordbug</td>\n",
       "      <td>allocine</td>\n",
       "      <td>7</td>\n",
       "      <td>Terrible histoire que ces êtres sans amour, ce...</td>\n",
       "      <td>Terirble histoire que ces êtres sans amour, ce...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.002917255973443389, 0.9970827698707581]</td>\n",
       "      <td>[0.562905490398407, 0.437094509601593]</td>\n",
       "      <td>success</td>\n",
       "      <td>86</td>\n",
       "      <td>0.027397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>deepwordbug</td>\n",
       "      <td>allocine</td>\n",
       "      <td>8</td>\n",
       "      <td>Un très joli film, qui ressemble à un téléfilm...</td>\n",
       "      <td>Un trè joli filV, qui ressemlbe à un téléfilm ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.003121939953416586, 0.9968780279159546]</td>\n",
       "      <td>[0.8752533793449402, 0.12474663555622101]</td>\n",
       "      <td>success</td>\n",
       "      <td>61</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>deepwordbug</td>\n",
       "      <td>allocine</td>\n",
       "      <td>9</td>\n",
       "      <td>Mais comment certaines personnes ont pus lui m...</td>\n",
       "      <td>Mais comment ceErtaines personnes ont pus lui ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9994810223579407, 0.0005190648953430355]</td>\n",
       "      <td>[0.9947376847267151, 0.0052623143419623375]</td>\n",
       "      <td>failed</td>\n",
       "      <td>294</td>\n",
       "      <td>0.165563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>deepwordbug</td>\n",
       "      <td>allocine</td>\n",
       "      <td>10</td>\n",
       "      <td>LE film de mon enfance , il a un peu vieilli m...</td>\n",
       "      <td>L film de on enfance , il a un peu vieilli mai...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0029145427979528904, 0.9970855116844177]</td>\n",
       "      <td>[0.6242376565933228, 0.37576231360435486]</td>\n",
       "      <td>success</td>\n",
       "      <td>138</td>\n",
       "      <td>0.077778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    scenario     target_model target_model_train_dataset attack_toolchain  \\\n",
       "0  sentiment  distilcamembert                   allocine       textattack   \n",
       "1  sentiment  distilcamembert                   allocine       textattack   \n",
       "2  sentiment  distilcamembert                   allocine       textattack   \n",
       "3  sentiment  distilcamembert                   allocine       textattack   \n",
       "4  sentiment  distilcamembert                   allocine       textattack   \n",
       "5  sentiment  distilcamembert                   allocine       textattack   \n",
       "6  sentiment  distilcamembert                   allocine       textattack   \n",
       "7  sentiment  distilcamembert                   allocine       textattack   \n",
       "8  sentiment  distilcamembert                   allocine       textattack   \n",
       "9  sentiment  distilcamembert                   allocine       textattack   \n",
       "\n",
       "   attack_name target_dataset  test_index  \\\n",
       "0  deepwordbug       allocine           0   \n",
       "1  deepwordbug       allocine           1   \n",
       "2  deepwordbug       allocine           2   \n",
       "3  deepwordbug       allocine           3   \n",
       "4  deepwordbug       allocine           4   \n",
       "5  deepwordbug       allocine           5   \n",
       "6  deepwordbug       allocine           7   \n",
       "7  deepwordbug       allocine           8   \n",
       "8  deepwordbug       allocine           9   \n",
       "9  deepwordbug       allocine          10   \n",
       "\n",
       "                                       original_text  \\\n",
       "0  Magnifique épopée, une belle histoire, touchan...   \n",
       "1  Je n'ai pas aimé mais pourtant je lui mets 2 é...   \n",
       "2  Un dessin animé qui brille par sa féerie et se...   \n",
       "3  Si c'est là le renouveau du cinéma français, c...   \n",
       "4  Et pourtant on s’en Doutait !Second volet très...   \n",
       "5  Vous reprendrez bien un peu d'été ? Ce film je...   \n",
       "6  Terrible histoire que ces êtres sans amour, ce...   \n",
       "7  Un très joli film, qui ressemble à un téléfilm...   \n",
       "8  Mais comment certaines personnes ont pus lui m...   \n",
       "9  LE film de mon enfance , il a un peu vieilli m...   \n",
       "\n",
       "                                      perturbed_text  ground_truth  \\\n",
       "0  Mcgnifique éApopée, une elle istoire, touclhan...             1   \n",
       "1  Je n'ai pms Yaimé mais pourtant je lui meVts 2...             0   \n",
       "2  Un dessin animé qui bille paT sa féerdie et se...             1   \n",
       "3  gi c'est là le renouveau du cinéma français, c...             0   \n",
       "4  t pourtant on s’Fn Doutait !eScond svolet trè ...             0   \n",
       "5  Vous reprendrez bien un peu d'été ? Ce film je...             1   \n",
       "6  Terirble histoire que ces êtres sans amour, ce...             1   \n",
       "7  Un trè joli filV, qui ressemlbe à un téléfilm ...             1   \n",
       "8  Mais comment ceErtaines personnes ont pus lui ...             0   \n",
       "9  L film de on enfance , il a un peu vieilli mai...             1   \n",
       "\n",
       "                               original_output  \\\n",
       "0   [0.0017641951562836766, 0.998235821723938]   \n",
       "1   [0.9981809854507446, 0.001819050288759172]   \n",
       "2    [0.006273656152188778, 0.993726372718811]   \n",
       "3  [0.9992220401763916, 0.0007778950384818017]   \n",
       "4  [0.9990242719650269, 0.0009757408406585455]   \n",
       "5  [0.0016408609226346016, 0.9983591437339783]   \n",
       "6   [0.002917255973443389, 0.9970827698707581]   \n",
       "7   [0.003121939953416586, 0.9968780279159546]   \n",
       "8  [0.9994810223579407, 0.0005190648953430355]   \n",
       "9  [0.0029145427979528904, 0.9970855116844177]   \n",
       "\n",
       "                              perturbed_output   status  num_queries  \\\n",
       "0     [0.6277955174446106, 0.3722044825553894]  success           78   \n",
       "1     [0.4200280010700226, 0.5799720287322998]  success           77   \n",
       "2    [0.8436582684516907, 0.15634173154830933]  success           24   \n",
       "3    [0.25986334681510925, 0.7401366233825684]  success           41   \n",
       "4       [0.236352801322937, 0.763647198677063]  success           64   \n",
       "5   [0.017444437369704247, 0.9825555086135864]   failed          512   \n",
       "6       [0.562905490398407, 0.437094509601593]  success           86   \n",
       "7    [0.8752533793449402, 0.12474663555622101]  success           61   \n",
       "8  [0.9947376847267151, 0.0052623143419623375]   failed          294   \n",
       "9    [0.6242376565933228, 0.37576231360435486]  success          138   \n",
       "\n",
       "   frac_words_changed  \n",
       "0            0.333333  \n",
       "1            0.065574  \n",
       "2            0.272727  \n",
       "3            0.107143  \n",
       "4            0.647059  \n",
       "5            0.081081  \n",
       "6            0.027397  \n",
       "7            0.266667  \n",
       "8            0.165563  \n",
       "9            0.077778  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"attacks/allocine/distilcamembert/textattack/deepwordbug/10/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:00:23\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total time: {time.strftime('%H:%M:%S', time.gmtime(time.time()-t))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-adversarial-attacks-ghBt6cj_-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
