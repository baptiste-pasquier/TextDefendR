{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3080\n",
      "Free memory : 8.9 / 10.0 GB\n",
      "\n",
      "Using TF32\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.utils import is_torch_tf32_available\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "assert len(tf.config.list_physical_devices(\"GPU\")) >= 1\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(\n",
    "    f\"Free memory : {round(torch.cuda.mem_get_info()[0] / 1024 ** 3,1)} / {round(torch.cuda.mem_get_info()[1] / 1024 ** 3,1)} GB\"\n",
    ")\n",
    "\n",
    "if is_torch_tf32_available():\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    print(\"\\nUsing TF32\")\n",
    "else:\n",
    "    print(\"\\nTF32 not available\")\n",
    "\n",
    "\n",
    "t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "dataset_path = \"allocine\"\n",
    "input_column = \"review\"\n",
    "label_column = \"label\"\n",
    "new_label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "train_split = \"train\"\n",
    "eval_split = \"validation\"\n",
    "test_split = \"test\"\n",
    "\n",
    "# Model\n",
    "model_checkpoint = \"cmarkea/distilcamembert-base\"\n",
    "output_model_name = \"distilcamembert-allocine\"\n",
    "output_dir = \"models/\" + output_model_name\n",
    "\n",
    "PUSH_TO_HUB = False\n",
    "\n",
    "# Training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=500,\n",
    "    logging_first_step=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"all\",\n",
    "    push_to_hub=PUSH_TO_HUB,\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "metrics = [\"accuracy\", \"f1\", \"precision\", \"recall\"]\n",
    "\n",
    "# Model card\n",
    "language = [\"fr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset allocine (C:/Users/Baptiste/.cache/huggingface/datasets/allocine/allocine/1.0.0/ea86b1dc05eae3a45a07b6281f2d4033b5fe7927b1008d06aa457ca1eae660d0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1553719e5c8f485fa6ef0897a09c231c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 160000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_label2id: {'neg': 0, 'pos': 1}\n",
      "label2id: {'NEGATIVE': 0, 'POSITIVE': 1}\n",
      "id2label: {0: 'NEGATIVE', 1: 'POSITIVE'}\n"
     ]
    }
   ],
   "source": [
    "print(\"old_label2id:\", dataset[\"train\"].features[\"label\"]._str2int)\n",
    "label2id = new_label2id\n",
    "\n",
    "id2label = {value: key for key, value in label2id.items()}\n",
    "\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Baptiste\\.cache\\huggingface\\datasets\\allocine\\allocine\\1.0.0\\ea86b1dc05eae3a45a07b6281f2d4033b5fe7927b1008d06aa457ca1eae660d0\\cache-ea4d286d3404735c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Baptiste\\.cache\\huggingface\\datasets\\allocine\\allocine\\1.0.0\\ea86b1dc05eae3a45a07b6281f2d4033b5fe7927b1008d06aa457ca1eae660d0\\cache-ef55e725dc732a08.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Baptiste\\.cache\\huggingface\\datasets\\allocine\\allocine\\1.0.0\\ea86b1dc05eae3a45a07b6281f2d4033b5fe7927b1008d06aa457ca1eae660d0\\cache-06b4ebe2acc3478d.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[input_column], truncation=True)\n",
    "\n",
    "\n",
    "encoded_dataset = dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[input_column]\n",
    ")\n",
    "train_dataset = encoded_dataset[train_split]\n",
    "eval_dataset = encoded_dataset[eval_split]\n",
    "test_dataset = encoded_dataset[test_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cmarkea/distilcamembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, label2id=label2id, id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = evaluate.combine(metrics)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return clf_metrics.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baptiste\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\huggingface-_cDAN_r4-py3.10\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 160000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 7500\n",
      "  Number of trainable parameters = 68096258\n",
      "You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7500/7500 1:13:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.128982</td>\n",
       "      <td>0.955450</td>\n",
       "      <td>0.954178</td>\n",
       "      <td>0.961447</td>\n",
       "      <td>0.947019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.133400</td>\n",
       "      <td>0.104950</td>\n",
       "      <td>0.962350</td>\n",
       "      <td>0.961898</td>\n",
       "      <td>0.953647</td>\n",
       "      <td>0.970294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.115800</td>\n",
       "      <td>0.105219</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>0.962743</td>\n",
       "      <td>0.949831</td>\n",
       "      <td>0.976011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>0.094924</td>\n",
       "      <td>0.966100</td>\n",
       "      <td>0.965277</td>\n",
       "      <td>0.968551</td>\n",
       "      <td>0.962025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.093568</td>\n",
       "      <td>0.966600</td>\n",
       "      <td>0.966337</td>\n",
       "      <td>0.954220</td>\n",
       "      <td>0.978767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.098741</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.969540</td>\n",
       "      <td>0.964351</td>\n",
       "      <td>0.974786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.107814</td>\n",
       "      <td>0.968800</td>\n",
       "      <td>0.968437</td>\n",
       "      <td>0.959795</td>\n",
       "      <td>0.977236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.105061</td>\n",
       "      <td>0.967300</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.955188</td>\n",
       "      <td>0.979175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.094024</td>\n",
       "      <td>0.970950</td>\n",
       "      <td>0.970395</td>\n",
       "      <td>0.968766</td>\n",
       "      <td>0.972029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.073300</td>\n",
       "      <td>0.103808</td>\n",
       "      <td>0.968550</td>\n",
       "      <td>0.968317</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.981217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.106577</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>0.970991</td>\n",
       "      <td>0.964826</td>\n",
       "      <td>0.977236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.109832</td>\n",
       "      <td>0.968950</td>\n",
       "      <td>0.968632</td>\n",
       "      <td>0.958704</td>\n",
       "      <td>0.978767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.111040</td>\n",
       "      <td>0.971100</td>\n",
       "      <td>0.970621</td>\n",
       "      <td>0.966592</td>\n",
       "      <td>0.974684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.114867</td>\n",
       "      <td>0.969700</td>\n",
       "      <td>0.969397</td>\n",
       "      <td>0.959224</td>\n",
       "      <td>0.979788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.112190</td>\n",
       "      <td>0.970300</td>\n",
       "      <td>0.969927</td>\n",
       "      <td>0.962133</td>\n",
       "      <td>0.977848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-500\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-500\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-1000\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-1000\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-1000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-1500\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-1500\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-1500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-2000\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-2000\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-2000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-2500\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-2500\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-2500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-3000\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-3000\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-3000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-3500\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-3500\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-3500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-4000\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-4000\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-4000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-4500\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-4500\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-4500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-5000\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-5000\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-5000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-5500\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-5500\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-5500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-6000\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-6000\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-6000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-6500\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-6500\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-6500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-7000\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-7000\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-7000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to models/distilcamembert-allocine\\checkpoint-7500\n",
      "Configuration saved in models/distilcamembert-allocine\\checkpoint-7500\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\checkpoint-7500\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from models/distilcamembert-allocine\\checkpoint-5500 (score: 0.9714).\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  total_flos               = 42405087GF\n",
      "  train_loss               =     0.0894\n",
      "  train_runtime            = 1:13:46.03\n",
      "  train_samples            =     160000\n",
      "  train_samples_per_second =    108.449\n",
      "  train_steps_per_second   =      1.695\n"
     ]
    }
   ],
   "source": [
    "train_metrics = train_results.metrics\n",
    "train_metrics[\"train_samples\"] = len(train_dataset)\n",
    "trainer.log_metrics(\"train\", train_metrics)\n",
    "trainer.save_metrics(\"train\", train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_accuracy           =     0.9714\n",
      "  eval_f1                 =      0.971\n",
      "  eval_loss               =     0.1066\n",
      "  eval_precision          =     0.9648\n",
      "  eval_recall             =     0.9772\n",
      "  eval_runtime            = 0:00:52.95\n",
      "  eval_samples            =      20000\n",
      "  eval_samples_per_second =    377.655\n",
      "  eval_steps_per_second   =     23.603\n"
     ]
    }
   ],
   "source": [
    "eval_metrics[\"eval_samples\"] = len(eval_dataset)\n",
    "trainer.log_metrics(\"eval\", eval_metrics)\n",
    "trainer.save_metrics(\"eval\", eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "test_output = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test metrics *****\n",
      "  test_accuracy           =     0.9704\n",
      "  test_f1                 =     0.9692\n",
      "  test_loss               =     0.1095\n",
      "  test_precision          =      0.966\n",
      "  test_recall             =     0.9724\n",
      "  test_runtime            = 0:00:54.56\n",
      "  test_samples            =      20000\n",
      "  test_samples_per_second =    366.503\n",
      "  test_steps_per_second   =     22.906\n"
     ]
    }
   ],
   "source": [
    "test_metrics = test_output.metrics\n",
    "test_metrics[\"test_samples\"] = len(test_dataset)\n",
    "trainer.log_metrics(\"test\", test_metrics)\n",
    "trainer.save_metrics(\"test\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()\n",
    "\n",
    "Path(output_dir, \"results\").mkdir(exist_ok=True)\n",
    "for file in [\n",
    "    \"all_results.json\",\n",
    "    \"train_results.json\",\n",
    "    \"eval_results.json\",\n",
    "    \"test_results.json\",\n",
    "    \"trainer_state.json\",\n",
    "]:\n",
    "    shutil.move(Path(output_dir, file), Path(output_dir, \"results\", file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models/distilcamembert-allocine\n",
      "Configuration saved in models/distilcamembert-allocine\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\pytorch_model.bin\n",
      "tokenizer config file saved in models/distilcamembert-allocine\\tokenizer_config.json\n",
      "Special tokens file saved in models/distilcamembert-allocine\\special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "if PUSH_TO_HUB:\n",
    "    trainer.push_to_hub(language=language)\n",
    "else:\n",
    "    trainer.save_model()\n",
    "    trainer.create_model_card(language=language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/distilcamembert-allocine\\config.json\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"models/distilcamembert-allocine\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "loading weights file models/distilcamembert-allocine\\pytorch_model.bin\n",
      "Loading PyTorch weights from C:\\Users\\Baptiste\\Github\\huggingface\\experiments\\distilcamembert\\16x4_5e5_3_500\\models\\distilcamembert-allocine\\pytorch_model.bin\n",
      "PyTorch checkpoint contains 68,096,772 parameters\n",
      "Loaded 68,096,258 parameters in the TF 2.0 model.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFCamembertForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFCamembertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFCamembertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFCamembertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertForSequenceClassification for predictions without further training.\n",
      "Configuration saved in models/distilcamembert-allocine\\config.json\n",
      "Model weights saved in models/distilcamembert-allocine\\tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    output_dir, from_pt=True\n",
    ")\n",
    "tf_model.config.__dict__[\"_name_or_path\"] = model_checkpoint\n",
    "# tf_model.push_to_hub(output_model_name) # modify README\n",
    "tf_model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 01:15:47\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total time: {time.strftime('%H:%M:%S', time.gmtime(time.time()-t))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
