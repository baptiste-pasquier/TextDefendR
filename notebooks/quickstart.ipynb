{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from textdefendr.encoder import TextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 9000 samples of attacks on Allociné + 20000 original reviews.\n",
    "\n",
    "The `attack_name` column shows the name of the attack used, or \"clean\" for original texts.\n",
    "\n",
    "The `perturbed_text` column contains the text modified by an attack, or the original text for unattacked samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Baptiste\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\textdefendr-4pBPr9rq-py3.10\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'dataset_info': token. Will not be supported from version '0.12'.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using custom data configuration baptiste-pasquier--attack-dataset-c656294678469f2e\n",
      "Reusing dataset csv (C:\\Users\\Baptiste\\.cache\\huggingface\\datasets\\baptiste-pasquier___csv\\baptiste-pasquier--attack-dataset-c656294678469f2e\\0.0.0\\652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>target_model</th>\n",
       "      <th>target_model_train_dataset</th>\n",
       "      <th>attack_toolchain</th>\n",
       "      <th>attack_name</th>\n",
       "      <th>target_dataset</th>\n",
       "      <th>test_index</th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>original_output</th>\n",
       "      <th>perturbed_output</th>\n",
       "      <th>status</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>frac_words_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10227</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>none</td>\n",
       "      <td>clean</td>\n",
       "      <td>allocine</td>\n",
       "      <td>10227</td>\n",
       "      <td>C'est un très bon film qui n'est pas seulement...</td>\n",
       "      <td>C'est un très bon film qui n'est pas seulement...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.56757518e-04 9.99543242e-01]</td>\n",
       "      <td>[4.56757518e-04 9.99543242e-01]</td>\n",
       "      <td>clean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7563</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>none</td>\n",
       "      <td>clean</td>\n",
       "      <td>allocine</td>\n",
       "      <td>7563</td>\n",
       "      <td>Avec ce Parrain 3, Coppola règle ses comptes, ...</td>\n",
       "      <td>Avec ce Parrain 3, Coppola règle ses comptes, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.26541245e-04 9.99573459e-01]</td>\n",
       "      <td>[4.26541245e-04 9.99573459e-01]</td>\n",
       "      <td>clean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23582</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>input_reduction</td>\n",
       "      <td>allocine</td>\n",
       "      <td>755</td>\n",
       "      <td>Pour ceux qui souhaiteraient prolonger le plai...</td>\n",
       "      <td>ceux souhaiteraient \"\", id à d'ados aux, donc,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.999473512172699, 0.0005264984210953116]</td>\n",
       "      <td>[0.9982336759567261, 0.0017663395265117288]</td>\n",
       "      <td>success</td>\n",
       "      <td>319</td>\n",
       "      <td>0.355670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22798</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>deepwordbug</td>\n",
       "      <td>allocine</td>\n",
       "      <td>2000</td>\n",
       "      <td>Probablement le film d'espionnage le plus inte...</td>\n",
       "      <td>Probableent le film d'espionnage le plus intel...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0008815607288852334, 0.9991183876991272]</td>\n",
       "      <td>[0.9320080280303955, 0.06799197196960449]</td>\n",
       "      <td>success</td>\n",
       "      <td>105</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>none</td>\n",
       "      <td>clean</td>\n",
       "      <td>allocine</td>\n",
       "      <td>6909</td>\n",
       "      <td>Très bon film d'horreur francais, du suspens ....</td>\n",
       "      <td>Très bon film d'horreur francais, du suspens ....</td>\n",
       "      <td>1</td>\n",
       "      <td>[9.58729705e-04 9.99041270e-01]</td>\n",
       "      <td>[9.58729705e-04 9.99041270e-01]</td>\n",
       "      <td>clean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>none</td>\n",
       "      <td>clean</td>\n",
       "      <td>allocine</td>\n",
       "      <td>8390</td>\n",
       "      <td>Mais dans quel guêpier sont allés se fourrer c...</td>\n",
       "      <td>Mais dans quel guêpier sont allés se fourrer c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[9.99811249e-01 1.88751290e-04]</td>\n",
       "      <td>[9.99811249e-01 1.88751290e-04]</td>\n",
       "      <td>clean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15354</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>none</td>\n",
       "      <td>clean</td>\n",
       "      <td>allocine</td>\n",
       "      <td>15354</td>\n",
       "      <td>Une comédie culte des années 70, l'age d'or de...</td>\n",
       "      <td>Une comédie culte des années 70, l'age d'or de...</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.38780759e-04 9.99461219e-01]</td>\n",
       "      <td>[5.38780759e-04 9.99461219e-01]</td>\n",
       "      <td>clean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>none</td>\n",
       "      <td>clean</td>\n",
       "      <td>allocine</td>\n",
       "      <td>843</td>\n",
       "      <td>Excellent, si j'avais un doute sur l'acteur (q...</td>\n",
       "      <td>Excellent, si j'avais un doute sur l'acteur (q...</td>\n",
       "      <td>1</td>\n",
       "      <td>[6.04682728e-04 9.99395317e-01]</td>\n",
       "      <td>[6.04682728e-04 9.99395317e-01]</td>\n",
       "      <td>clean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14907</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>none</td>\n",
       "      <td>clean</td>\n",
       "      <td>allocine</td>\n",
       "      <td>14907</td>\n",
       "      <td>On est très loin du chef-d’œuvre annoncé, cert...</td>\n",
       "      <td>On est très loin du chef-d’œuvre annoncé, cert...</td>\n",
       "      <td>0</td>\n",
       "      <td>[9.99792352e-01 2.07648342e-04]</td>\n",
       "      <td>[9.99792352e-01 2.07648342e-04]</td>\n",
       "      <td>clean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25609</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>allocine</td>\n",
       "      <td>textattack</td>\n",
       "      <td>textbugger</td>\n",
       "      <td>allocine</td>\n",
       "      <td>20</td>\n",
       "      <td>Le dernier Marvel exploite la franchise Spider...</td>\n",
       "      <td>Le dernier Marvel exploite la franchise Spider...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9995710253715515, 0.0004289315256755799]</td>\n",
       "      <td>[0.22022633254528046, 0.7797737121582031]</td>\n",
       "      <td>success</td>\n",
       "      <td>74</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scenario     target_model target_model_train_dataset attack_toolchain  \\\n",
       "10227  sentiment  distilcamembert                   allocine             none   \n",
       "7563   sentiment  distilcamembert                   allocine             none   \n",
       "23582  sentiment  distilcamembert                   allocine       textattack   \n",
       "22798  sentiment  distilcamembert                   allocine       textattack   \n",
       "6909   sentiment  distilcamembert                   allocine             none   \n",
       "...          ...              ...                        ...              ...   \n",
       "8390   sentiment  distilcamembert                   allocine             none   \n",
       "15354  sentiment  distilcamembert                   allocine             none   \n",
       "843    sentiment  distilcamembert                   allocine             none   \n",
       "14907  sentiment  distilcamembert                   allocine             none   \n",
       "25609  sentiment  distilcamembert                   allocine       textattack   \n",
       "\n",
       "           attack_name target_dataset  test_index  \\\n",
       "10227            clean       allocine       10227   \n",
       "7563             clean       allocine        7563   \n",
       "23582  input_reduction       allocine         755   \n",
       "22798      deepwordbug       allocine        2000   \n",
       "6909             clean       allocine        6909   \n",
       "...                ...            ...         ...   \n",
       "8390             clean       allocine        8390   \n",
       "15354            clean       allocine       15354   \n",
       "843              clean       allocine         843   \n",
       "14907            clean       allocine       14907   \n",
       "25609       textbugger       allocine          20   \n",
       "\n",
       "                                           original_text  \\\n",
       "10227  C'est un très bon film qui n'est pas seulement...   \n",
       "7563   Avec ce Parrain 3, Coppola règle ses comptes, ...   \n",
       "23582  Pour ceux qui souhaiteraient prolonger le plai...   \n",
       "22798  Probablement le film d'espionnage le plus inte...   \n",
       "6909   Très bon film d'horreur francais, du suspens ....   \n",
       "...                                                  ...   \n",
       "8390   Mais dans quel guêpier sont allés se fourrer c...   \n",
       "15354  Une comédie culte des années 70, l'age d'or de...   \n",
       "843    Excellent, si j'avais un doute sur l'acteur (q...   \n",
       "14907  On est très loin du chef-d’œuvre annoncé, cert...   \n",
       "25609  Le dernier Marvel exploite la franchise Spider...   \n",
       "\n",
       "                                          perturbed_text  ground_truth  \\\n",
       "10227  C'est un très bon film qui n'est pas seulement...             1   \n",
       "7563   Avec ce Parrain 3, Coppola règle ses comptes, ...             1   \n",
       "23582  ceux souhaiteraient \"\", id à d'ados aux, donc,...             0   \n",
       "22798  Probableent le film d'espionnage le plus intel...             1   \n",
       "6909   Très bon film d'horreur francais, du suspens ....             1   \n",
       "...                                                  ...           ...   \n",
       "8390   Mais dans quel guêpier sont allés se fourrer c...             0   \n",
       "15354  Une comédie culte des années 70, l'age d'or de...             1   \n",
       "843    Excellent, si j'avais un doute sur l'acteur (q...             1   \n",
       "14907  On est très loin du chef-d’œuvre annoncé, cert...             0   \n",
       "25609  Le dernier Marvel exploite la franchise Spider...             0   \n",
       "\n",
       "                                   original_output  \\\n",
       "10227              [4.56757518e-04 9.99543242e-01]   \n",
       "7563               [4.26541245e-04 9.99573459e-01]   \n",
       "23582   [0.999473512172699, 0.0005264984210953116]   \n",
       "22798  [0.0008815607288852334, 0.9991183876991272]   \n",
       "6909               [9.58729705e-04 9.99041270e-01]   \n",
       "...                                            ...   \n",
       "8390               [9.99811249e-01 1.88751290e-04]   \n",
       "15354              [5.38780759e-04 9.99461219e-01]   \n",
       "843                [6.04682728e-04 9.99395317e-01]   \n",
       "14907              [9.99792352e-01 2.07648342e-04]   \n",
       "25609  [0.9995710253715515, 0.0004289315256755799]   \n",
       "\n",
       "                                  perturbed_output   status  num_queries  \\\n",
       "10227              [4.56757518e-04 9.99543242e-01]    clean            0   \n",
       "7563               [4.26541245e-04 9.99573459e-01]    clean            0   \n",
       "23582  [0.9982336759567261, 0.0017663395265117288]  success          319   \n",
       "22798    [0.9320080280303955, 0.06799197196960449]  success          105   \n",
       "6909               [9.58729705e-04 9.99041270e-01]    clean            0   \n",
       "...                                            ...      ...          ...   \n",
       "8390               [9.99811249e-01 1.88751290e-04]    clean            0   \n",
       "15354              [5.38780759e-04 9.99461219e-01]    clean            0   \n",
       "843                [6.04682728e-04 9.99395317e-01]    clean            0   \n",
       "14907              [9.99792352e-01 2.07648342e-04]    clean            0   \n",
       "25609    [0.22022633254528046, 0.7797737121582031]  success           74   \n",
       "\n",
       "       frac_words_changed  \n",
       "10227            0.000000  \n",
       "7563             0.000000  \n",
       "23582            0.355670  \n",
       "22798            0.045455  \n",
       "6909             0.000000  \n",
       "...                   ...  \n",
       "8390             0.000000  \n",
       "15354            0.000000  \n",
       "843              0.000000  \n",
       "14907            0.000000  \n",
       "25609            0.071429  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_dataset(\"baptiste-pasquier/attack-dataset\", split=\"all\").to_pandas()\n",
    "df = df.sample(1000, random_state=42)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a binary classification model, we can consider the binary variable that indicates whether a text comes from an attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"perturbed_text\"]\n",
    "y = df[\"attack_name\"] != \"clean\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode text samples with several language model embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b66c524589e423792ec3cf5cead0edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding text properties with sentence-transformers/bert-base-nli-mean-tokens...\n",
      "Encoding perplexity with gpt2...\n",
      "Encoding proba and rank with roberta-base...\n"
     ]
    }
   ],
   "source": [
    "encoder = TextEncoder(\n",
    "    enable_tp=True, enable_lm_perplexity=True, enable_lm_proba=True, device=device\n",
    ")\n",
    "X_train_encoded = encoder.fit_transform(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is possible to use any usual classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1fd698f7cf4bd48f41a85eb9b7ff21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding text properties with sentence-transformers/bert-base-nli-mean-tokens...\n",
      "Encoding perplexity with gpt2...\n",
      "Encoding proba and rank with roberta-base...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.745"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_encoded = encoder.transform(X_test)\n",
    "clf.score(X_test_encoded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-adversarial-attacks-ghBt6cj_-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
