{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nlp_adversarial_attacks.utils.file_io import load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_infos(metrics_path):\n",
    "    parts = metrics_path.parts\n",
    "    infos = {\n",
    "        \"dataset\": parts[-6],\n",
    "        \"target_model\": parts[-5],\n",
    "        \"setting\": parts[-4],\n",
    "        \"classification_model\": parts[-3],\n",
    "        \"feature_setting\": parts[-2],\n",
    "    }\n",
    "    return infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_tcab\\detection-experiments\\allocine\\distilcamembert\\clean_vs_all\\LR\\all\\metrics.json\n",
      "data_tcab\\detection-experiments\\allocine\\distilcamembert\\clean_vs_all\\LR\\bert\\metrics.json\n",
      "data_tcab\\detection-experiments\\allocine\\distilcamembert\\clean_vs_all\\LR\\bert+tp\\metrics.json\n",
      "data_tcab\\detection-experiments\\allocine\\distilcamembert\\clean_vs_all\\LR\\bert+tp+lm\\metrics.json\n",
      "data_tcab\\detection-experiments\\allocine\\distilcamembert\\multiclass_with_clean\\LR\\all\\metrics.json\n",
      "data_tcab\\detection-experiments\\allocine\\distilcamembert\\multiclass_with_clean\\LR\\bert\\metrics.json\n",
      "data_tcab\\detection-experiments\\allocine\\distilcamembert\\multiclass_with_clean\\LR\\bert+tp\\metrics.json\n",
      "data_tcab\\detection-experiments\\allocine\\distilcamembert\\multiclass_with_clean\\LR\\bert+tp+lm\\metrics.json\n"
     ]
    }
   ],
   "source": [
    "all_experiments_dir = Path(\"data_tcab/detection-experiments/\")\n",
    "\n",
    "df_list = []\n",
    "for metrics_path in all_experiments_dir.glob(\"**/metrics.json\"):\n",
    "    print(metrics_path)\n",
    "    infos = extract_infos(metrics_path)\n",
    "    metrics = load_json(metrics_path)\n",
    "    infos.update(metrics)\n",
    "    df_list.append(infos)\n",
    "\n",
    "df = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>target_model</th>\n",
       "      <th>setting</th>\n",
       "      <th>classification_model</th>\n",
       "      <th>feature_setting</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_balanced_accuracy</th>\n",
       "      <th>train_confusion_matrix</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_confusion_matrix</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>best_params</th>\n",
       "      <th>label_classes</th>\n",
       "      <th>important_features</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>coef</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allocine</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>clean_vs_all</td>\n",
       "      <td>LR</td>\n",
       "      <td>all</td>\n",
       "      <td>0.660414</td>\n",
       "      <td>0.688911</td>\n",
       "      <td>[[4579, 779], [2860, 2498]]</td>\n",
       "      <td>0.660414</td>\n",
       "      <td>0.658043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738845</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>[[1712, 297], [458, 424]]</td>\n",
       "      <td>0.666445</td>\n",
       "      <td>None</td>\n",
       "      <td>[clean, perturbed]</td>\n",
       "      <td>{'perturbed': [['lm_perplexity_region3', 5.365...</td>\n",
       "      <td>[lm_perplexity_region0, lm_perplexity_region1,...</td>\n",
       "      <td>[[-1.6938213413066278e-07, 1.5353975152925724e...</td>\n",
       "      <td>[-4.600471193939136e-07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allocine</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>clean_vs_all</td>\n",
       "      <td>LR</td>\n",
       "      <td>bert</td>\n",
       "      <td>0.756719</td>\n",
       "      <td>0.757532</td>\n",
       "      <td>[[4205, 1153], [1454, 3904]]</td>\n",
       "      <td>0.756719</td>\n",
       "      <td>0.702475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725700</td>\n",
       "      <td>0.685698</td>\n",
       "      <td>[[1533, 476], [317, 565]]</td>\n",
       "      <td>0.701828</td>\n",
       "      <td>None</td>\n",
       "      <td>[clean, perturbed]</td>\n",
       "      <td>{'perturbed': [['lm_bert_730', 1.4868903882966...</td>\n",
       "      <td>[lm_bert_0, lm_bert_1, lm_bert_2, lm_bert_3, l...</td>\n",
       "      <td>[[0.2663386936328011, 0.04088693145206867, -0....</td>\n",
       "      <td>[-0.23563552424318304]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allocine</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>clean_vs_all</td>\n",
       "      <td>LR</td>\n",
       "      <td>bert+tp</td>\n",
       "      <td>0.680384</td>\n",
       "      <td>0.682606</td>\n",
       "      <td>[[3941, 1417], [2008, 3350]]</td>\n",
       "      <td>0.680384</td>\n",
       "      <td>0.689258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703909</td>\n",
       "      <td>0.670858</td>\n",
       "      <td>[[1449, 560], [296, 586]]</td>\n",
       "      <td>0.692827</td>\n",
       "      <td>None</td>\n",
       "      <td>[clean, perturbed]</td>\n",
       "      <td>{'perturbed': [['num_lowercase_letters_after_p...</td>\n",
       "      <td>[avg_word_length_mean_region0, avg_word_length...</td>\n",
       "      <td>[[0.006650055163060376, -0.00518692983647272, ...</td>\n",
       "      <td>[0.005120431487314478]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allocine</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>clean_vs_all</td>\n",
       "      <td>LR</td>\n",
       "      <td>bert+tp+lm</td>\n",
       "      <td>0.676558</td>\n",
       "      <td>0.692233</td>\n",
       "      <td>[[4390, 968], [2498, 2860]]</td>\n",
       "      <td>0.676558</td>\n",
       "      <td>0.676603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735386</td>\n",
       "      <td>0.686961</td>\n",
       "      <td>[[1640, 369], [396, 486]]</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>None</td>\n",
       "      <td>[clean, perturbed]</td>\n",
       "      <td>{'perturbed': [['lm_perplexity_region3', 3.948...</td>\n",
       "      <td>[lm_perplexity_region0, lm_perplexity_region1,...</td>\n",
       "      <td>[[-3.254680695673622e-07, 1.5717863471986165e-...</td>\n",
       "      <td>[-3.592934595064093e-07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allocine</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>multiclass_with_clean</td>\n",
       "      <td>LR</td>\n",
       "      <td>all</td>\n",
       "      <td>0.161803</td>\n",
       "      <td>0.168826</td>\n",
       "      <td>[[55, 0, 37, 279, 297, 6, 77], [138, 0, 44, 47...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057420</td>\n",
       "      <td>0.051607</td>\n",
       "      <td>[[10, 0, 8, 41, 45, 2, 10], [205, 0, 77, 877, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[bae, clean, deepwordbug, input_reduction, pww...</td>\n",
       "      <td>{'bae': [['lm_perplexity_region0', 4.596773654...</td>\n",
       "      <td>[lm_perplexity_region0, lm_perplexity_region1,...</td>\n",
       "      <td>[[4.596773654379349e-06, -1.1090316033952182e-...</td>\n",
       "      <td>[1.4633797663186693e-09, 1.6546024621122676e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>allocine</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>multiclass_with_clean</td>\n",
       "      <td>LR</td>\n",
       "      <td>bert</td>\n",
       "      <td>0.581665</td>\n",
       "      <td>0.566470</td>\n",
       "      <td>[[364, 129, 51, 24, 64, 50, 69], [273, 453, 10...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.335632</td>\n",
       "      <td>[[37, 26, 10, 8, 9, 11, 15], [398, 698, 230, 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[bae, clean, deepwordbug, input_reduction, pww...</td>\n",
       "      <td>{'bae': [['lm_bert_308', 0.6792810934692531], ...</td>\n",
       "      <td>[lm_bert_0, lm_bert_1, lm_bert_2, lm_bert_3, l...</td>\n",
       "      <td>[[0.14161254231483408, -0.1918526514989975, -0...</td>\n",
       "      <td>[0.10088610415918736, 0.09111927961940826, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>allocine</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>multiclass_with_clean</td>\n",
       "      <td>LR</td>\n",
       "      <td>bert+tp</td>\n",
       "      <td>0.447212</td>\n",
       "      <td>0.428890</td>\n",
       "      <td>[[290, 74, 65, 99, 30, 107, 86], [275, 162, 10...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.449977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243860</td>\n",
       "      <td>0.279479</td>\n",
       "      <td>[[48, 7, 5, 13, 11, 14, 18], [434, 251, 154, 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[bae, clean, deepwordbug, input_reduction, pww...</td>\n",
       "      <td>{'bae': [['num_words', 0.05435910747334989], [...</td>\n",
       "      <td>[avg_word_length_mean_region0, avg_word_length...</td>\n",
       "      <td>[[-0.00693362469778088, -0.018202735273793756,...</td>\n",
       "      <td>[0.0014393302536597475, -0.0015508184792321672...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allocine</td>\n",
       "      <td>distilcamembert</td>\n",
       "      <td>multiclass_with_clean</td>\n",
       "      <td>LR</td>\n",
       "      <td>bert+tp+lm</td>\n",
       "      <td>0.161039</td>\n",
       "      <td>0.168624</td>\n",
       "      <td>[[59, 0, 36, 269, 305, 5, 77], [144, 0, 44, 46...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057420</td>\n",
       "      <td>0.052928</td>\n",
       "      <td>[[11, 0, 9, 36, 47, 1, 12], [228, 0, 80, 845, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[bae, clean, deepwordbug, input_reduction, pww...</td>\n",
       "      <td>{'bae': [['lm_perplexity_region0', 4.379971535...</td>\n",
       "      <td>[lm_perplexity_region0, lm_perplexity_region1,...</td>\n",
       "      <td>[[4.379971535162992e-06, -1.0763771033089494e-...</td>\n",
       "      <td>[1.412717289814511e-09, 1.5974093257425439e-09...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset     target_model                setting classification_model  \\\n",
       "0  allocine  distilcamembert           clean_vs_all                   LR   \n",
       "1  allocine  distilcamembert           clean_vs_all                   LR   \n",
       "2  allocine  distilcamembert           clean_vs_all                   LR   \n",
       "3  allocine  distilcamembert           clean_vs_all                   LR   \n",
       "4  allocine  distilcamembert  multiclass_with_clean                   LR   \n",
       "5  allocine  distilcamembert  multiclass_with_clean                   LR   \n",
       "6  allocine  distilcamembert  multiclass_with_clean                   LR   \n",
       "7  allocine  distilcamembert  multiclass_with_clean                   LR   \n",
       "\n",
       "  feature_setting  train_accuracy  train_balanced_accuracy  \\\n",
       "0             all        0.660414                 0.688911   \n",
       "1            bert        0.756719                 0.757532   \n",
       "2         bert+tp        0.680384                 0.682606   \n",
       "3      bert+tp+lm        0.676558                 0.692233   \n",
       "4             all        0.161803                 0.168826   \n",
       "5            bert        0.581665                 0.566470   \n",
       "6         bert+tp        0.447212                 0.428890   \n",
       "7      bert+tp+lm        0.161039                 0.168624   \n",
       "\n",
       "                              train_confusion_matrix  train_roc_auc  \\\n",
       "0                        [[4579, 779], [2860, 2498]]       0.660414   \n",
       "1                       [[4205, 1153], [1454, 3904]]       0.756719   \n",
       "2                       [[3941, 1417], [2008, 3350]]       0.680384   \n",
       "3                        [[4390, 968], [2498, 2860]]       0.676558   \n",
       "4  [[55, 0, 37, 279, 297, 6, 77], [138, 0, 44, 47...            NaN   \n",
       "5  [[364, 129, 51, 24, 64, 50, 69], [273, 453, 10...            NaN   \n",
       "6  [[290, 74, 65, 99, 30, 107, 86], [275, 162, 10...            NaN   \n",
       "7  [[59, 0, 36, 269, 305, 5, 77], [144, 0, 44, 46...            NaN   \n",
       "\n",
       "   validation_accuracy  ...  test_accuracy test_balanced_accuracy  \\\n",
       "0             0.658043  ...       0.738845               0.688506   \n",
       "1             0.702475  ...       0.725700               0.685698   \n",
       "2             0.689258  ...       0.703909               0.670858   \n",
       "3             0.676603  ...       0.735386               0.686961   \n",
       "4             0.164915  ...       0.057420               0.051607   \n",
       "5             0.514847  ...       0.408163               0.335632   \n",
       "6             0.449977  ...       0.243860               0.279479   \n",
       "7             0.166743  ...       0.057420               0.052928   \n",
       "\n",
       "                               test_confusion_matrix  test_roc_auc  \\\n",
       "0                          [[1712, 297], [458, 424]]      0.666445   \n",
       "1                          [[1533, 476], [317, 565]]      0.701828   \n",
       "2                          [[1449, 560], [296, 586]]      0.692827   \n",
       "3                          [[1640, 369], [396, 486]]      0.683673   \n",
       "4  [[10, 0, 8, 41, 45, 2, 10], [205, 0, 77, 877, ...           NaN   \n",
       "5  [[37, 26, 10, 8, 9, 11, 15], [398, 698, 230, 1...           NaN   \n",
       "6  [[48, 7, 5, 13, 11, 14, 18], [434, 251, 154, 2...           NaN   \n",
       "7  [[11, 0, 9, 36, 47, 1, 12], [228, 0, 80, 845, ...           NaN   \n",
       "\n",
       "   best_params                                      label_classes  \\\n",
       "0         None                                 [clean, perturbed]   \n",
       "1         None                                 [clean, perturbed]   \n",
       "2         None                                 [clean, perturbed]   \n",
       "3         None                                 [clean, perturbed]   \n",
       "4         None  [bae, clean, deepwordbug, input_reduction, pww...   \n",
       "5         None  [bae, clean, deepwordbug, input_reduction, pww...   \n",
       "6         None  [bae, clean, deepwordbug, input_reduction, pww...   \n",
       "7         None  [bae, clean, deepwordbug, input_reduction, pww...   \n",
       "\n",
       "                                  important_features  \\\n",
       "0  {'perturbed': [['lm_perplexity_region3', 5.365...   \n",
       "1  {'perturbed': [['lm_bert_730', 1.4868903882966...   \n",
       "2  {'perturbed': [['num_lowercase_letters_after_p...   \n",
       "3  {'perturbed': [['lm_perplexity_region3', 3.948...   \n",
       "4  {'bae': [['lm_perplexity_region0', 4.596773654...   \n",
       "5  {'bae': [['lm_bert_308', 0.6792810934692531], ...   \n",
       "6  {'bae': [['num_words', 0.05435910747334989], [...   \n",
       "7  {'bae': [['lm_perplexity_region0', 4.379971535...   \n",
       "\n",
       "                                       feature_names  \\\n",
       "0  [lm_perplexity_region0, lm_perplexity_region1,...   \n",
       "1  [lm_bert_0, lm_bert_1, lm_bert_2, lm_bert_3, l...   \n",
       "2  [avg_word_length_mean_region0, avg_word_length...   \n",
       "3  [lm_perplexity_region0, lm_perplexity_region1,...   \n",
       "4  [lm_perplexity_region0, lm_perplexity_region1,...   \n",
       "5  [lm_bert_0, lm_bert_1, lm_bert_2, lm_bert_3, l...   \n",
       "6  [avg_word_length_mean_region0, avg_word_length...   \n",
       "7  [lm_perplexity_region0, lm_perplexity_region1,...   \n",
       "\n",
       "                                                coef  \\\n",
       "0  [[-1.6938213413066278e-07, 1.5353975152925724e...   \n",
       "1  [[0.2663386936328011, 0.04088693145206867, -0....   \n",
       "2  [[0.006650055163060376, -0.00518692983647272, ...   \n",
       "3  [[-3.254680695673622e-07, 1.5717863471986165e-...   \n",
       "4  [[4.596773654379349e-06, -1.1090316033952182e-...   \n",
       "5  [[0.14161254231483408, -0.1918526514989975, -0...   \n",
       "6  [[-0.00693362469778088, -0.018202735273793756,...   \n",
       "7  [[4.379971535162992e-06, -1.0763771033089494e-...   \n",
       "\n",
       "                                           intercept  \n",
       "0                           [-4.600471193939136e-07]  \n",
       "1                             [-0.23563552424318304]  \n",
       "2                             [0.005120431487314478]  \n",
       "3                           [-3.592934595064093e-07]  \n",
       "4  [1.4633797663186693e-09, 1.6546024621122676e-0...  \n",
       "5  [0.10088610415918736, 0.09111927961940826, -0....  \n",
       "6  [0.0014393302536597475, -0.0015508184792321672...  \n",
       "7  [1.412717289814511e-09, 1.5974093257425439e-09...  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-adversarial-attacks-ghBt6cj_-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
