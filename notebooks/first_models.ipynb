{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data_tcab/whole_feature_dataset.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_features = df.columns[df.columns.str.startswith(\"tp_\")].tolist()\n",
    "tp_bert_features = df.columns[df.columns.str.startswith(\"tp_bert_\")].tolist()\n",
    "lm_features = df.columns[df.columns.str.startswith(\"lm_\")].tolist()\n",
    "tm_features = df.columns[df.columns.str.startswith(\"tm_\")].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars = [\n",
    "    \"unique_id\",\n",
    "    \"attack_name\",\n",
    "    \"attack_toolchain\",\n",
    "    \"attack_id\",\n",
    "    \"scenario\",\n",
    "    \"target_model\",\n",
    "    \"target_model_dataset\",\n",
    "    \"attack_id_bis\",\n",
    "]\n",
    "index_df = df.loc[:, id_vars]\n",
    "index_df[\"label\"] = np.where(index_df[\"attack_name\"] == \"clean\", 0, 1)\n",
    "var_df = df.drop(id_vars, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx, y_train, y_test = train_test_split(\n",
    "    var_df.index,\n",
    "    index_df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=index_df[\"label\"],\n",
    ")\n",
    "X_train, X_test = var_df.loc[train_idx], var_df.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(), PCA(100), LogisticRegression(max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    feature_subset = trial.suggest_categorical(\n",
    "        \"feature_subset\",\n",
    "        [\"tp_features\", \"tp_bert_features\", \"lm_features\", \"tm_features\"],\n",
    "    )\n",
    "    feature_dict = {\n",
    "        \"tp_bert_features\": tp_bert_features,\n",
    "        \"tp_features\": tp_features,\n",
    "        \"lm_features\": tp_features + lm_features,\n",
    "        \"tm_features\": tp_features + lm_features + tm_features,\n",
    "    }\n",
    "    feature_selector = ColumnTransformer(\n",
    "        transformers=[(\"selector\", \"passthrough\", feature_dict[feature_subset])],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "\n",
    "    classifier_name = trial.suggest_categorical(\n",
    "        \"classifier\", [\"LogisticRegression\", \"XGBoost\"]\n",
    "    )\n",
    "    if classifier_name == \"LogisticRegression\":\n",
    "        lr_c = trial.suggest_float(\"lr_c\", 1e-10, 1e10, log=True)\n",
    "        lr_penalty = trial.suggest_categorical(\"lr_penalty\", [None, \"l1\", \"l2\"])\n",
    "        classifier_obj = sklearn.linear_model.LogisticRegression(\n",
    "            C=lr_c, penalty=lr_penalty, solver=\"saga\", max_iter=1000\n",
    "        )\n",
    "    elif classifier_name == \"XGBoost\":\n",
    "        xgb_max_depth = trial.suggest_int(\"xgb_max_depth\", 2, 32, log=True)\n",
    "        xgb_n_estimators = trial.suggest_int(\"xgb_n_estimators\", 10, 500, log=True)\n",
    "        classifier_obj = XGBClassifier(\n",
    "            max_depth=xgb_max_depth, n_estimators=xgb_n_estimators\n",
    "        )\n",
    "\n",
    "    scaler_name = trial.suggest_categorical(\n",
    "        \"scaler\", [\"None\", \"StandardScaler\", \"StandardScaler+PCA\"]\n",
    "    )\n",
    "    if scaler_name == \"None\":\n",
    "        preprocessor = Pipeline([(\"preprocessor\", \"passthrough\")])\n",
    "    elif scaler_name == \"StandardScaler\":\n",
    "        preprocessor = Pipeline([(\"scaler\", StandardScaler())])\n",
    "    elif scaler_name == \"StandardScaler+PCA\":\n",
    "        pca_n_components = trial.suggest_int(\"pca_n_components\", 25, 250, log=True)\n",
    "        preprocessor = Pipeline(\n",
    "            [(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=pca_n_components))]\n",
    "        )\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"selector\", feature_selector),\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", classifier_obj),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True, n_jobs=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-adversarial-attacks-qj5liwpn-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
